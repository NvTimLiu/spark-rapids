#!/usr/local/env groovy
/*
 * Copyright (c) 2020-2024, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 *
 * Jenkinsfile for building rapids-plugin on blossom
 *
 */
import hudson.model.Result
import hudson.model.Run
import jenkins.model.CauseOfInterruption.UserInterruption

@Library('blossom-lib')
@Library('blossom-github-lib@master')
import ipp.blossom.*

def TEMP_IMAGE_BUILD = true
def CUDA_NAME = 'cuda11.0.3' // hardcode cuda version for docker build part
def PREMERGE_DOCKERFILE = 'jenkins/Dockerfile-blossom.ubuntu'
def IMAGE_PREMERGE="urm.nvidia.com/sw-spark-docker-local/plugin:dev-ubuntu20-$CUDA_NAME-blossom-dev" // temp image for premerge test
def IMAGE_DB = pod.getCPUYAML("${common.ARTIFACTORY_NAME}/sw-spark-docker/spark:rapids-databricks")
def PREMERGE_TAG
def skipped = false
def db_build = true
def sourcePattern = 'shuffle-plugin/src/main/scala/,udf-compiler/src/main/scala/,' +
    'sql-plugin/src/main/java/,sql-plugin/src/main/scala/'

pipeline {
    agent {
        kubernetes {
            label "premerge-init-${BUILD_TAG}"
            cloud "${common.CLOUD_NAME}"
            yaml "${IMAGE_DB}"
        }
    }

    options {
        ansiColor('xterm')
        buildDiscarder(logRotator(numToKeepStr: '50'))
        skipDefaultCheckout true
        timeout(time: 12, unit: 'HOURS')
    }

    parameters {
        // Put a default value for REF to avoid error when running the pipeline manually
        string(name: 'REF', defaultValue: 'main',
            description: 'Merged commit of specific PR')
        string(name: 'GITHUB_DATA', defaultValue: '',
            description: 'Json-formatted github data from upstream blossom-ci')
    }

    environment {
        JENKINS_ROOT = 'jenkins'
        PREMERGE_SCRIPT = '$JENKINS_ROOT/spark-premerge-build.sh'
        MVN_URM_MIRROR = '-s jenkins/settings.xml -P mirror-apache-to-urm'
        LIBCUDF_KERNEL_CACHE_PATH = '/tmp/.cudf'
        ARTIFACTORY_NAME = "${common.ARTIFACTORY_NAME}"
        GITHUB_TOKEN = credentials("github-token")
        URM_CREDS = credentials("urm_creds")
        URM_URL = "https://${common.ARTIFACTORY_NAME}/artifactory/sw-spark-maven"
        PVC = credentials("pvc")
        CUSTOM_WORKSPACE = "/home/jenkins/agent/workspace/${BUILD_TAG}"
        CLASSIFIER = 'cuda11'
    }

    stages {
        stage('checkout') {
            steps {
                script {
                    common.checkoutSourceCode(this, 'https://github.com/NvTimLiu/spark-rapids.git', 'test-speedup')
                    sh "git submodule update --init --recursive"
                    if (!common.isSubmoduleInit(this)) {
                        error "Failed to clone submodule : thirdparty/parquet-testing"
                    }
                    stash(name: "source_tree", includes: "**,.git/**", useDefaultExcludes: false)
                }
            }
        }

        stage('Premerge Test') {
            // Parallel run mvn verify (build and integration tests) and unit tests (for multiple Spark versions)
            // If any one is failed will abort another if not finish yet and will upload failure log to Github
            failFast true
            parallel {
                stage('mvn verify') {
                    when {
                        beforeAgent true
                        beforeOptions true
                        expression { params.STAGE == 'mvn_verify' }
                    }
                    options {
                        // We have to use params to pass the resource label in options block,
                        // this is a limitation of declarative pipeline. And we need to lock resource before agent start
                        lock(label: "${params.GPU_POOL}", quantity: 1, variable: 'GPU_RESOURCE')
                    }
                    agent {
                        kubernetes {
                            label "premerge-ci-1-${BUILD_TAG}"
                            cloud "${common.CLOUD_NAME}"
                            yaml pod.getGPUYAML("${IMAGE_PREMERGE}", "${env.GPU_RESOURCE}", '8', '32Gi')
                            workspaceVolume persistentVolumeClaimWorkspaceVolume(claimName: "${PVC}", readOnly: false)
                            customWorkspace "${CUSTOM_WORKSPACE}"
                        }
                    }

                    steps {
                        script {
                            unstash "source_tree"
                            container('gpu') {
                                timeout(time: 4, unit: 'HOURS') { // step only timeout for test run
sh "nproc || true"
sh "lsmem || true"
sh "nvidia-smi || true"
                                    sh "$PREMERGE_SCRIPT mvn_verify"
                                    deleteDir() // cleanup content if no error
                                }
                            }
                        }
                    }
                } // end of mvn verify stage

                stage('Premerge CI 2') {
                    options {
                        lock(label: "${params.GPU_POOL}", quantity: 1, variable: 'GPU_RESOURCE')
                    }
                    agent {
                        kubernetes {
                            label "premerge-ci-2-${BUILD_TAG}"
                            cloud "${common.CLOUD_NAME}"
                            yaml pod.getGPUYAML("${IMAGE_PREMERGE}", "${env.GPU_RESOURCE}", '8', '32Gi')
                            workspaceVolume persistentVolumeClaimWorkspaceVolume(claimName: "${PVC}", readOnly: false)
                            customWorkspace "${CUSTOM_WORKSPACE}-ci-2" // Use different workspace to avoid conflict with IT
                        }
                    }

                    steps {
                        script {
                            unstash "source_tree"
                            container('gpu') {
                                timeout(time: 4, unit: 'HOURS') {
sh "nproc || true"
sh "lsmem || true"
sh "nvidia-smi || true"
                                    sh "$PREMERGE_SCRIPT ci_2"
                                    deleteDir() // cleanup content if no error
                                }
                            }
                        }
                    }
                } // end of Unit Test stage

                stage('CI scala 2.13') {
                    when {
                        beforeAgent true
                        beforeOptions true
                        expression { params.STAGE == 'mvn_verify' }
                    }
                    options {
                        lock(label: "${params.GPU_POOL}", quantity: 1, variable: 'GPU_RESOURCE')
                    }
                    agent {
                        kubernetes {
                            label "ci-scala213-${BUILD_TAG}"
                            cloud "${common.CLOUD_NAME}"
                            yaml pod.getGPUYAML("${IMAGE_PREMERGE}", "${env.GPU_RESOURCE}", '8', '32Gi')
                            workspaceVolume persistentVolumeClaimWorkspaceVolume(claimName: "${PVC}", readOnly: false)
                            customWorkspace "${CUSTOM_WORKSPACE}-scala-213" // Use different workspace to avoid conflict with IT
                        }
                    }

                    steps {
                        script {
                            unstash "source_tree"
                            container('gpu') {
                                timeout(time: 4, unit: 'HOURS') {
sh "nproc || true"
sh "lsmem || true"
sh "nvidia-smi || true"
                                    sh "$PREMERGE_SCRIPT ci_scala213"
                                    deleteDir() // cleanup content if no error
                                }
                            }
                        }
                    }
                } // end of Unit Test stage

                stage('Dummy stage: blue ocean log view') {
                    steps {
                        echo "workaround for blue ocean bug https://issues.jenkins.io/browse/JENKINS-48879"
                    }
                } // Dummy stage
            } // end of parallel
        } // end of Premerge Test
    } // end of stages
} // end of pipeline
