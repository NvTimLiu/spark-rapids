#!/usr/local/env groovy
/*
 * Copyright (c) 2019-2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
*
* Jenkinsfile for building and deploy rapids-plugin to public repo
*
*/
@Library('shared-libs') _

def urmUrl="https://${ArtifactoryConstants.ARTIFACTORY_NAME}/artifactory/sw-spark-maven"

pipeline {
    agent { label 'docker-deploy||docker-gpu' }

    options {
        ansiColor('xterm')
        timeout(time: 180, unit: 'MINUTES')
        buildDiscarder(logRotator(numToKeepStr: '10'))
    }

    parameters {
        string(name: 'DEPLOY_TO', defaultValue: 'http://apt-sh04:8081/repository/xgboost-spark-release',
            description: 'The repo URL where to deploy the artifacts')
        string(name: 'REPO_ID', defaultValue: 'spark.sw.nvidia.com', description: 'Repo ID')
        string(name: 'REF', defaultValue: 'databricks-tim', description: 'Commit to build')
    }

    environment {
        JENKINS_ROOT='jenkins'
        IMAGE_NAME="${ArtifactoryConstants.ARTIFACTORY_NAME}/sw-spark-docker/plugin:dev-ubuntu16-cuda10.1"
        LIBCUDF_KERNEL_CACHE_PATH='/tmp/.cudf'
        MVN_MIRROR='-s jenkins/settings.xml -P mirror-apache-to-urm'
        DIST_PL='dist'
        SQL_PL='sql-plugin'
        URM_URL = "${urmUrl}"
    }

    stages {
        stage ("Prepare databricks shims") {
            steps {
                build(job: 'tim-plugin-test/', propagate: true, parameters: [string(name: 'REF', value: "$REF")])
            }
        }
        stage('Build') {
            steps {
                script {
                    sh "docker pull $IMAGE_NAME"
                    sh "mkdir -p ${HOME}/.zinc"
                    echo "USER : ${USER}, HOME: $HOME"
                    docker.image("$IMAGE_NAME").inside("--runtime=nvidia -v ${HOME}/.m2:${HOME}/.m2:rw \
                        -v ${HOME}/.zinc:${HOME}/.zinc:rw") {
                        echo "USER : ${USER}, HOME: $HOME"
                        //sh "mvn -U -B -Dmaven.repo.local=${HOME}/.m2/repository clean install $MVN_MIRROR -P 'include-databricks,source-javadoc,!snapshot-shims' -DskipTests"
                    }
                }
            }
        }

        stage("Deploy") {
            environment {
                SERVER_ID="${REPO_ID}"
                SERVER_URL="${DEPLOY_TO}"
                GPG_PASSPHRASE=credentials('SPARK_RAPIDS_GPG_PASSPHRASE')
                GPG_FILE=credentials('SPARK_RAPIDS_GPG_PRIVATE_KEY')
                SONATYPE=credentials('SPARK_SONATYPE_USERPASS')
                GNUPGHOME="${WORKSPACE}/.gnupg"
            }
            steps {
                script {
                    echo "USER : ${USER}, HOME: $HOME"
                    docker.image("$IMAGE_NAME").inside("-v ${HOME}/.m2:${HOME}/.m2:rw") {
                        sh 'rm -rf $GNUPGHOME'
                        echo "USER : ${USER}, HOME: $HOME"
                        sh 'gpg --import $GPG_FILE'
                        retry (1) {
                            sh "bash $JENKINS_ROOT/deploy.sh true false"
                        }
                    }
                }
            }
        }
    } // End of stages

}

